{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTHVhzg81xeZ"
      },
      "source": [
        "# Deep Reinforcement Learning\n",
        "\n",
        "Deep Q-Learning or Deep Q-Network (DQN)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBrqUJF-tW83",
        "outputId": "aa71f4dc-d1cd-47ab-c8b9-6450e9a3ce30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gymnasium\n",
            "  Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting farama-notifications>=0.0.1\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Collecting jax-jumpy>=1.0.0\n",
            "  Downloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.22.4)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.5.0)\n",
            "Installing collected packages: farama-notifications, jax-jumpy, gymnasium\n",
            "Successfully installed farama-notifications-0.0.4 gymnasium-0.28.1 jax-jumpy-1.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.0.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.22.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (8.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.39.3)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common\n",
            "The following NEW packages will be installed:\n",
            "  libfontenc1 libxfont2 libxkbfile1 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 9 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 7,697 kB of archives.\n",
            "After this operation, 11.9 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal/main amd64 libfontenc1 amd64 1:1.1.4-0ubuntu1 [14.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal/main amd64 libxfont2 amd64 1:2.0.3-1 [91.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal/main amd64 libxkbfile1 amd64 1:1.1.0-1 [65.3 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal/main amd64 x11-xkb-utils amd64 7.7+5 [158 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu1 [573 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-utils amd64 1:7.7+6 [91.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 xserver-common all 2:1.20.13-1ubuntu1~20.04.8 [27.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 xvfb amd64 2:1.20.13-1ubuntu1~20.04.8 [780 kB]\n",
            "Fetched 7,697 kB in 1s (5,694 kB/s)\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "(Reading database ... 122518 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libfontenc1_1%3a1.1.4-0ubuntu1_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../1-libxfont2_1%3a2.0.3-1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.3-1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../2-libxkbfile1_1%3a1.1.0-1_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../3-x11-xkb-utils_7.7+5_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../4-xfonts-encodings_1%3a1.0.5-0ubuntu1_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu1) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../5-xfonts-utils_1%3a7.7+6_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../6-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../7-xserver-common_2%3a1.20.13-1ubuntu1~20.04.8_all.deb ...\n",
            "Unpacking xserver-common (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../8-xvfb_2%3a1.20.13-1ubuntu1~20.04.8_amd64.deb ...\n",
            "Unpacking xvfb (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-0ubuntu1) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.3-1) ...\n",
            "Setting up x11-xkb-utils (7.7+5) ...\n",
            "Setting up xfonts-utils (1:7.7+6) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up xserver-common (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Setting up xvfb (2:1.20.13-1ubuntu1~20.04.8) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-2ubuntu3) ...\n",
            "Processing triggers for libc-bin (2.31-0ubuntu9.9) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gymnasium[box2d] in /usr/local/lib/python3.10/dist-packages (0.28.1)\n",
            "Collecting pytorch-lightning==1.6.0\n",
            "  Downloading pytorch_lightning-1.6.0-py3-none-any.whl (582 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.1/582.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyvirtualdisplay\n",
            "  Downloading PyVirtualDisplay-3.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: torch>=1.8.* in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.0) (2.0.0+cu118)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.0) (2.12.2)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.0) (2023.4.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.0) (4.65.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.0) (4.5.0)\n",
            "Collecting torchmetrics>=0.4.1\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyDeprecate<0.4.0,>=0.3.1\n",
            "  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.0) (23.1)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.6.0) (6.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (2.2.1)\n",
            "Requirement already satisfied: jax-jumpy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (1.0.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium[box2d]) (0.0.4)\n",
            "Collecting box2d-py==2.3.5\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pygame==2.1.3\n",
            "  Downloading pygame-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting swig==4.*\n",
            "  Downloading swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (0.7.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.0.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (0.40.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (2.17.3)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (3.20.3)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (2.3.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.54.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.6.0) (3.4.3)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.*->pytorch-lightning==1.6.0) (3.12.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.*->pytorch-lightning==1.6.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.*->pytorch-lightning==1.6.0) (16.0.2)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (2.0.12)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (4.9)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.16.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (1.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.0) (1.26.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.*->pytorch-lightning==1.6.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.2.0->pytorch-lightning==1.6.0) (3.2.2)\n",
            "Building wheels for collected packages: box2d-py\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for box2d-py\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for box2d-py\n",
            "Failed to build box2d-py\n",
            "Installing collected packages: swig, pyvirtualdisplay, box2d-py, pygame, pyDeprecate, multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, torchmetrics, pytorch-lightning\n",
            "  Running setup.py install for box2d-py ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: box2d-py was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. pip 23.1 will enforce this behaviour change. A possible replacement is to fix the wheel build issue reported above. Discussion can be found at https://github.com/pypa/pip/issues/8368\u001b[0m\u001b[33m\n",
            "\u001b[0m  Attempting uninstall: pygame\n",
            "    Found existing installation: pygame 2.3.0\n",
            "    Uninstalling pygame-2.3.0:\n",
            "      Successfully uninstalled pygame-2.3.0\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 box2d-py-2.3.5 frozenlist-1.3.3 multidict-6.0.4 pyDeprecate-0.3.2 pygame-2.1.3 pytorch-lightning-1.6.0 pyvirtualdisplay-3.0 swig-4.1.1 torchmetrics-0.11.4 yarl-1.9.2\n"
          ]
        }
      ],
      "source": [
        "! pip install gymnasium\n",
        "! pip install matplotlib\n",
        "!apt-get install -y xvfb\n",
        "!pip install gymnasium[box2d] pytorch-lightning==1.6.0 pyvirtualdisplay\n",
        "# !pip install https://github.com/PyTorchLightning/pytorch-lightning/archive/refs/heads/release/1.5.x.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules and packages\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "# Define a function for displaying videos in Jupyter notebooks\n",
        "def display_video(episode=0):\n",
        "    # Read the video file as binary data\n",
        "    video_file = open(f'/content/videos/rl-video-episode-{episode}.mp4', \"r+b\").read()\n",
        "    # Encode the video data in base64 format\n",
        "    video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "    # Return an HTML object that displays the video in the notebook\n",
        "    return HTML(f\"<video width=600 controls><source src='{video_url}'></video>\")\n"
      ],
      "metadata": {
        "id": "UFd8UxzH7CfV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function for creating a new OpenAI Gym environment\n",
        "def create_environment(name):\n",
        "    # Create a new environment object using the specified name\n",
        "    env = gym.make(name)\n",
        "    # Set a maximum number of steps per episode\n",
        "    env = TimeLimit(env, max_episode_steps=400)\n",
        "    # Record a video of the environment every 100 episodes\n",
        "    record_interval = 100\n",
        "    env = RecordVideo(env, video_folder='./videos', episode_trigger=lambda x: x % record_interval == 0)\n",
        "    # Record episode statistics such as reward, length, and time\n",
        "    env = RecordEpisodeStatistics(env)\n",
        "    # Return the modified environment object\n",
        "    return env\n"
      ],
      "metadata": {
        "id": "AhVO7aaE7Ejg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary modules and packages\n",
        "import copy\n",
        "import gym\n",
        "import torch\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from collections import deque, namedtuple\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "from torch import Tensor, nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.dataset import IterableDataset\n",
        "from torch.optim import AdamW\n",
        "\n",
        "from pytorch_lightning import LightningModule, Trainer\n",
        "from pytorch_lightning.callbacks import EarlyStopping\n",
        "\n",
        "from gym.wrappers import RecordVideo, RecordEpisodeStatistics, TimeLimit\n",
        "\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "\n",
        "# Check whether CUDA is available and select the device accordingly\n",
        "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Get the number of available GPUs\n",
        "num_gpus = torch.cuda.device_count()\n",
        "\n",
        "# Print the device and number of GPUs to the console\n",
        "print(device, num_gpus)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpLMqJMN7kvc",
        "outputId": "c2729d02-dd22-488d-ae75-99fbadf85e39"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/__init__.py:38: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('pytorch_lightning')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  __import__(\"pkg_resources\").declare_namespace(__name__)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaL9CGb_tW86"
      },
      "source": [
        "# LunarLander-v2\n",
        "\n",
        "In this project, a deep Q-learning algorithm is used to train an agent to play the LunarLander-v2 game from Gymnasium. LunarLander-v2 is a classic control task in which the agent is required to land a spacecraft safely on the moon's surface while controlling its speed and orientation. The game is considered solved when the agent successfully lands the spacecraft.\n",
        "\n",
        "\n",
        "Install [gym](https://github.com/openai/gym) or \n",
        "[gymnasium](https://gymnasium.farama.org/)_ for the environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "LP0hQeZMtW87",
        "outputId": "5c32d28a-e7f2-4275-8685-bc0f9ecfcfd1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Import the necessary modules and packages\n",
        "from IPython.display import clear_output\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a new environment object using the 'LunarLander-v2' environment from OpenAI Gym\n",
        "env = create_environment('LunarLander-v2')\n",
        "\n",
        "# Reset the environment to its initial state\n",
        "env.reset()\n",
        "\n",
        "# Test the environment's observation and action spaces\n",
        "env.observation_space.sample()\n",
        "env.action_space.sample()\n",
        "print(\"action_space_n=\", env.action_space.n)\n",
        "\n",
        "# Take a certain number of steps in the environment and display each frame as an image\n",
        "num_steps = 100 # number of steps to take\n",
        "steps_per_frame = 15 # number of steps to take per frame\n",
        "for i in range(num_steps // steps_per_frame):\n",
        "    clear_output(wait=True) # clear previous output\n",
        "    for j in range(steps_per_frame):\n",
        "        action = env.action_space.sample() # sample an action from the action space\n",
        "        observation, reward, done, info = env.step(action) # take a step in the environment using the sampled action\n",
        "    plt.imshow(env.render(mode='rgb_array'))\n",
        "    plt.show()\n",
        "    time.sleep(0.01) # pause for a short time between frames\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWMJFuk469E3",
        "outputId": "9d7c691b-9a78-40bf-ec0c-1dab2d1871d1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Nk_DucWtW88",
        "outputId": "ed577c4d-d51f-40cd-c198-8676be1a5d4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/core.py:317: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n",
            "  deprecation(\n"
          ]
        }
      ],
      "source": [
        "import math\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "env = gym.make(\"LunarLander-v2\")\n",
        "\n",
        "# set up matplotlib\n",
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "\n",
        "plt.ion()\n",
        "\n",
        "# if gpu is to be used\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "v5djcifBtW8-"
      },
      "outputs": [],
      "source": [
        "class DQN(nn.Module):\n",
        "\n",
        "    def __init__(self, n_observations, n_actions):\n",
        "        super(DQN, self).__init__()\n",
        "        self.layer1 = nn.Linear(n_observations, 128)\n",
        "        self.layer2 = nn.Linear(128, 128)\n",
        "        self.layer3 = nn.Linear(128, n_actions)\n",
        "\n",
        "    # Called with either one element to determine next action, or a batch\n",
        "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.layer1(x))\n",
        "        x = F.relu(self.layer2(x))\n",
        "        return self.layer3(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0CCgHKgqtW8_"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import namedtuple, deque\n",
        "from itertools import count\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "# BATCH_SIZE is the number of transitions sampled from the replay buffer\n",
        "# GAMMA is the discount factor as mentioned in the previous section\n",
        "# EPS_START is the starting value of epsilon\n",
        "# EPS_END is the final value of epsilon\n",
        "# EPS_DECAY controls the rate of exponential decay of epsilon, higher means a slower decay\n",
        "# TAU is the update rate of the target network\n",
        "# LR is the learning rate of the AdamW optimizer\n",
        "BATCH_SIZE = 128\n",
        "GAMMA = 0.99\n",
        "EPS_START = 0.9\n",
        "EPS_END = 0.05\n",
        "EPS_DECAY = 1000\n",
        "TAU = 0.005\n",
        "LR = 1e-4\n",
        "\n",
        "# Get number of actions from gym action space\n",
        "n_actions = env.action_space.n\n",
        "# Get the number of state observations\n",
        "state = env.reset()\n",
        "n_observations = len(state)\n",
        "\n",
        "policy_net = DQN(n_observations, n_actions).to(device)\n",
        "target_net = DQN(n_observations, n_actions).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict()) # a copy of q-function(dnns) Q old -\n",
        "\n",
        "# Replay Memory\n",
        "# We'll be using experience replay memory for training our DQN. It stores the transitions that the agent observes, \n",
        "# allowing us to reuse this data later. By sampling from it randomly, the transitions that build up a batch are decorrelated. \n",
        "# It has been shown that this greatly stabilizes and improves the DQN training procedure.\n",
        "Transition = namedtuple('Transition',\n",
        "                        ('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.memory = deque([], maxlen=capacity)\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Save a transition\"\"\"\n",
        "        self.memory.append(Transition(*args))\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)\n",
        "\n",
        "\n",
        "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
        "memory = ReplayMemory(10000)\n",
        "\n",
        "\n",
        "steps_done = 0\n",
        "\n",
        "\n",
        "def select_action(state):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
        "        math.exp(-1. * steps_done / EPS_DECAY)\n",
        "    steps_done += 1\n",
        "    if sample > eps_threshold:\n",
        "        with torch.no_grad():\n",
        "            # t.max(1) will return the largest column value of each row.\n",
        "            # second column on max result is index of where max element was\n",
        "            # found, so we pick action with the larger expected reward.\n",
        "            return policy_net(state).max(1)[1].view(1, 1)\n",
        "    else:\n",
        "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
        "\n",
        "\n",
        "# Store episode durations and rewards for plotting\n",
        "episode_durations = []\n",
        "episode_rewards = []\n",
        "reward_episode = []\n",
        "duration_episode = []\n",
        "\n",
        "# Plot episode rewards and durations during training\n",
        "def plot_durations(reward_episode, duration_episode, show_result=False):\n",
        "    plt.figure(1, figsize=[25, 8])\n",
        "    if show_result:\n",
        "        plt.title('Result')\n",
        "    else:\n",
        "        plt.clf()\n",
        "        plt.title('Training...')\n",
        "    plt.clf()\n",
        "    plt.subplot(121)\n",
        "    plt.title('Episode reward')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Reward')\n",
        "    plt.plot(reward_episode, 'b')\n",
        "    plt.subplot(122)\n",
        "    plt.title('Episode duration')\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Duration')\n",
        "    plt.plot(duration_episode, 'r')\n",
        "    plt.pause(0.001)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "    if is_ipython:\n",
        "        if not show_result:\n",
        "            display.display(plt.gcf())\n",
        "            display.clear_output(wait=True)\n",
        "        else:\n",
        "            display.display(plt.gcf())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u-9FxHE6tW9A"
      },
      "outputs": [],
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
        "    # detailed explanation). This converts batch-array of Transitions\n",
        "    # to Transition of batch-arrays.\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    # Compute a mask of non-final states and concatenate the batch elements\n",
        "    # (a final state would've been the one after which simulation ended)\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                                if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
        "    # columns of actions taken. These are the actions which would've been taken\n",
        "    # for each batch state according to policy_net\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch) # current Q\n",
        "\n",
        "    # Compute V(s_{t+1}) for all next states.\n",
        "    # Expected values of actions for non_final_next_states are computed based\n",
        "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
        "    # This is merged based on the mask, such that we'll have either the expected\n",
        "    # state value or 0 in case the state was final.\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    with torch.no_grad():\n",
        "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0]\n",
        "    # Compute the expected Q values\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch # r + dis * Q(s')\n",
        "\n",
        "    # Compute Huber loss\n",
        "    criterion = nn.SmoothL1Loss()\n",
        "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1)) # different current q -  new q\n",
        "\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    # In-place gradient clipping\n",
        "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
        "    optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9G4sOh1sgWwL"
      },
      "outputs": [],
      "source": [
        "\n",
        "    \n",
        "#remove \" > /dev/null 2>&1\" to see what is going on under the hood\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "\n",
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers.record_video import RecordVideo\n",
        "gymlogger.set_level(40) #error only\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import math\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "from IPython import display as ipythondisplay"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import os\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "import pylab as pl\n",
        "import pandas as pd\n",
        "from IPython import display as ipythondisplay\n",
        "%matplotlib inline\n",
        "from IPython.display import clear_output"
      ],
      "metadata": {
        "id": "WtKM1eAo8T31"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "a4VscitrhOZX"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment and displaying it\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  mp4list = glob.glob('/content/video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "    \n",
        "\n",
        "def wrap_env(env):\n",
        "  env = RecordVideo(env, '/content/video',  episode_trigger = lambda episode_number: True)\n",
        "  return env\n",
        "\n",
        "env = wrap_env(env)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQLlaetwo4ZX",
        "outputId": "3934aff5-2d4f-41e3-b08d-9205ee5abe3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7fd66d3192a0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from pyvirtualdisplay import Display\n",
        "display2 = Display(visible=0, size=(1400, 900))\n",
        "display2.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azqQfd3i5Yqk",
        "outputId": "c20d7103-4533-47cf-ee7e-bef581e9d887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    num_episodes = 600\n",
        "else:\n",
        "    num_episodes = 200\n",
        "\n",
        "for i_episode in range(num_episodes):\n",
        "    # Initialize the environment and get its state\n",
        "    state = env.reset()\n",
        "    state = torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "    for t in count():\n",
        "        action = select_action(state) # trade-off between exploration and exploitation. action = env.action_space.sample() pure exploration\n",
        "        observation, reward, terminated, _ = env.step(action.item())\n",
        "        reward = torch.tensor([reward], device=device)\n",
        "        done = terminated\n",
        "\n",
        "        if terminated:\n",
        "            next_state = None\n",
        "        else:\n",
        "            next_state = torch.tensor(observation, dtype=torch.float32, device=device).unsqueeze(0)\n",
        "\n",
        "        # Store the transition in memory\n",
        "        memory.push(state, action, next_state, reward)\n",
        "\n",
        "        # Move to the next state\n",
        "        state = next_state\n",
        "\n",
        "        # Perform one step of the optimization (on the policy network)\n",
        "        optimize_model()\n",
        "\n",
        "        # Soft update of the target network's weights\n",
        "        # θ′ ← τ θ + (1 −τ )θ′\n",
        "        target_net_state_dict = target_net.state_dict()\n",
        "        policy_net_state_dict = policy_net.state_dict()\n",
        "        for key in policy_net_state_dict:\n",
        "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
        "        target_net.load_state_dict(target_net_state_dict)\n",
        "\n",
        "        if done:\n",
        "          # Append episode reward and duration to their respective lists\n",
        "          durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
        "          durations_t.numpy()\n",
        "          episode_durations.append(t + 1)\n",
        "\n",
        "          rewards_t = torch.tensor(episode_rewards, dtype=torch.float)\n",
        "          rewards_t.numpy()\n",
        "          episode_rewards.append(reward.item())\n",
        "\n",
        "          show_video()\n",
        "          print(num_episodes)\n",
        "\n",
        "          plot_durations(rewards_t.numpy(), durations_t.numpy())\n",
        "\n",
        "          break\n",
        "    if i_episode % 25 == 0:\n",
        "      print(i_episode, reward)\n",
        "\n",
        "    if i_episode % 50 == 0:\n",
        "        for v in os.listdir('/content/video'):\n",
        "            os.remove('/content/video/' + v)\n",
        "        show_video()\n",
        "\n",
        "print('Complete after ', num_episodes, \" episodes\")\n",
        "print(episode_rewards)\n",
        "plot_durations(rewards_t.numpy(), durations_t.numpy(), show_result=True)\n",
        "plt.ioff()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}